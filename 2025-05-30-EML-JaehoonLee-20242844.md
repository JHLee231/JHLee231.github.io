
# Title: LoRA-RL: Low-Rank Adaptation Enables Fast, Transferable Reinforcement Learning for Analog Circuit Optimization


## Abstract

Analog-circuit sizing via graph-convolutional reinforcement learning (GCN-RL) has shown promise, but every new topology or process node demands thousands of fresh SPICE evaluations to retrain the agent from scratch. We present **LoRA-RL**, a parameter-efficient framework that attaches low-rank adaptation (LoRA) modules to a pretrained GCN-RL backbone and fine-tunes **only** these tiny rank-\(r\) matrices when transferring to a new circuit **or a shrunk process node**. On four different amplifiers, LoRA-RL reduces simulation cost by up to **XX %** while *improving* the final Figure-of-Merit compared with full GCN-RL retraining. Ablation studies show that LoRA stabilization yields a **A √ó** gain in sample efficiency and halves the rate of malfunctional SPICE runs. All code, netlists, and hyper-parameters will be released to encourage reproducibility and to slash weeks of re-sizing effort when a foundry releases the next node.



## 1‚ÄÉIntroduction

Analog-transistor sizing remains one of the most time-consuming and **skill-intensive** bottlenecks in custom-silicon design: taping out even a modest op-amp can absorb weeks of senior-level effort and millions of SPICE evaluations.  
Because successful sizing hinges on tacit analog know-how‚Äîdevice-level trade-offs, stability intuition, biasing tricks‚Äîthat takes **years of apprenticeship** to acquire, the workload cannot be scaled simply by adding more junior engineers.

Graph-Convolutional Reinforcement Learning (**GCN-RL**) has emerged as a promising alternative, exploiting circuit topology to learn sizing policies directly from simulation feedback. Yet **every time a new topology or, more commonly, a new process node arrives (e.g., 65 nm ‚Üí 28 nm ‚Üí 14 nm), design teams must re-train the agent from scratch**, incurring thousands of additional SPICE runs under tight tape-out schedules.

We observe that the physical priors captured by a well-trained GCN policy on one circuit‚Äìnode pair are largely reusable for others; only a compact subset of the parameters needs adapting. To exploit this redundancy, we introduce **LoRA-RL**, a parameter-efficient framework that  

1. **Pre-trains a GCN-RL policy** on a *reference circuit* in an older node and freezes its backbone weights.  
2. **Attaches low-rank adaptation (LoRA) modules** to every graph-convolution and projection layer, fine-tuning *only* these tiny rank-\(r\) matrices when transferring to a new circuit **or a shrunk process node** (Figure&nbsp;1).

Across four industrial-grade amplifiers, LoRA-RL cuts simulation time by up to **XX %** relative to full GCN-RL retraining while *improving* the final Figure-of-Merit (FoM). Ablation studies further show that low-rank re-parameterisation stabilises gradients in malfunctional regions and yields a **A √ó** boost in sample efficiency.

### Contributions

* **LoRA-GCN formulation.** We recast analog sizing as *parameter-efficient* RL by inserting LoRA adapters into a topology-aware GCN backbone.  
* **Cross-node transfer in hours.** Pre-training once and fine-tuning only LoRA parameters enables rapid migration to the next foundry node, slashing weeks of manual re-sizing.  
* **Two-phase training schedule.** Offline pre-training followed by online low-rank refinement accelerates convergence on unseen topologies or processes.  
* **State-of-the-art performance.** Experiments show higher FoM and an order-of-magnitude reduction in SPICE calls versus vanilla GCN-RL.  


![](fig/FIG1.png){ width=80% }

**Figure 1.** A GCN backbone is pre-trained on a reference circuit; only the low-rank LoRA modules are fine-tuned when transferring to new circuits or process nodes.

**Limitations.** Our current study focuses on a *schematic-level* optimisation and therefore leaves several practical issues open:

* **No layout parasitics.** Post-layout RC extraction and routing-induced loading are not modelled; the policy may need further tuning once layout is complete.  
* **Process & mismatch variations.** We size devices at nominal PDK corners only; Monte-Carlo and corner analysis are not yet integrated into the reward.  
* **AC/DC metrics only.** The reward considers gain, GBW, power and phase margin, but omits transient behaviour such as slew-rate and large-signal settling.  


## 2‚ÄÉBackground & Related Work

### 2.1‚ÄÉAnalog Circuit Optimization  
Traditional analog sizing pipelines depend on expert heuristics followed by large SPICE sweeps. Early automation framed the task as **black-box vector optimization**, applying Bayesian or evolutionary search directly to width/length vectors, but these methods scale poorly with design-space dimensionality and cannot reuse knowledge across circuits or process shrinks.

### 2.2‚ÄÉGraph-Convolutional Reinforcement Learning (GCN-RL)  
**GCN-RL** treats a netlist as a graph‚Äîtransistors become nodes, wires form edges‚Äîand trains an actor‚Äìcritic agent on simulation feedback. While it outperforms Bayesian Opt. and CMA-ES on its seed circuit, two limitations appear when transferring to new topologies or smaller nodes:  

* **Sample inefficiency**: hundreds‚Äìthousands of fresh SPICE runs are still needed before convergence.  
* **Full-parameter fine-tuning**: every GCN weight is updated, so time and memory overhead grow with backbone size.

One-hop aggregation also risks long-range information loss, causing over-smoothing in deeper layers.

![](fig/FIG2.png){ width=80% }
**Figure 2.** Reinforcement learning agent with multi-layer GCN from reference


### 2.3‚ÄÉParameter-Efficient Transfer with Low-Rank Adaptation  
**Low-Rank Adaptation (LoRA)** freezes the pretrained backbone \(W_0\) and learns only a rank-\(r\) update \(ŒîW = AB\) (\(A‚àà‚Ñù^{d_{out}√ór},\;B‚àà‚Ñù^{r√ód_{in}}\)). In NLP and vision this slashes train-time compute while matching full fine-tune accuracy. We posit that a GCN-RL policy likewise captures reusable physical priors; adapting only a low-rank sub-space should (i) stabilise gradients in the vast malfunctional region and (ii) cut SPICE calls required for transfer.

Our **LoRA-RL** framework therefore marries the topology awareness of GCN-RL with LoRA‚Äôs parameter efficiency, aiming to keep GCN-RL‚Äôs FoM gains while eliminating its fine-tuning overhead.

---


## 3‚ÄÉLoRA-RL Method

### 3.1‚ÄÉProblem Formulation  
Given a fixed netlist \(\mathcal{C}\) with \(n\) continuous sizing parameters  
\[
x \;=\; [W_1/L_1,\,\dots,\,W_n/L_n]^\top\in\mathbb{R}^n,
\]
our goal is to maximise a designer-defined Figure-of-Merit (FoM)
\[
\text{FoM}(x)= (w_\text{GBW}\text{ GBW})^2 /(w_\text{power}\text{ power}\ )
\]
subject to hard constraints such as phase-margin \(\ge 60^\circ\) and PDK bounds on device dimensions.  
We cast this as a continuous-action reinforcement-learning problem: the **state** is the circuit graph annotated with current device sizes and key AC/DC metrics such as gain, bandwidth, and power; the **action** is a perturbation \(\Delta x\); the **reward** is the change in FoM plus a penalty for infeasible operating points.

---

### 3.2‚ÄÉGCN Backbone with LoRA  
We follow the topology-aware policy architecture of GCN-RL[^gcn-rl]:

* **Node features**  
  * *Transistor type* (NMOS, PMOS)  
  * *Resistance* of device-level or elements  
  * *Capacitance* (device capacitors and loading capacitancs)  
  * *Transistor size* ‚Äî width \(W\) and length \(L\) (continuous)  

* **Edge features**: net type (signal, bias, supply/ground) and DC voltage drop.  
* **GCN layers**: three stacked graph convolutions with ReLU and layer norm.

To enable parameter-efficient transfer, we **freeze all backbone weights**
\(W_0\) **after pre-training** and attach rank-\(r\) LoRA adapters to every linear projection:

\[
W = W_0 + A B,\quad
A\in\mathbb{R}^{d_\text{out}\times r},\;
B\in\mathbb{R}^{r\times d_\text{in}},\qquad r\ll d_\text{in}.
\]

Only \(A,B\) (‚âà 0.7 % of total parameters when \(r=4\)) are updated during fine-tuning, leaving \(W_0\) intact‚Äîthis is visually summarised in **Figure&nbsp;1**.


---

### 3.3‚ÄÉTraining Procedure  

| Phase | What is trained | Episodes | Replay buffer |
|-------|-----------------|----------|---------------|
| **1. Pre-train** | **All** GCN-RL parameters | ‚âà 10 000 | Grows normally |
| **2. Transfer**  | **LoRA adapters only** | 200 ‚Äì 500 | Reset to empty |

```text
Algorithm 1‚ÄÉLoRA-RL two-phase training (GCN-RL backbone)

Input: reference circuit ùíû‚ÇÄ, target circuit ùíû·µ¢
 1:  # ---------- Phase 1: Pre-train ----------
 2:  Initialise actor œÄŒ∏ and critic QœÜ with GCN layers
 3:  for t = 1 ‚Ä¶ 10 000 episodes do
 4:      Roll out œÄŒ∏ on simulator of ùíû‚ÇÄ
 5:      Store (s, a, r, s‚Ä≤) into replay buffer ùîÖ
 6:      Update Œ∏, œÜ using **same actor-critic rule as original GCN-RL**
 7:  end for
 8:  Freeze backbone weights W‚ÇÄ          ‚Üê Œ∏ now fixed
 9:  Insert rank-r LoRA matrices (A,B)  ‚Üê trainable
10:  Reset replay buffer ùîÖ ‚Üê ‚àÖ
11:  # ---------- Phase 2: Transfer ----------
12:  for t = 1 ‚Ä¶ K‚Ä≤ episodes (K‚Ä≤‚âà200) do
13:      Roll out œÄŒ∏‚Ä≤ (backbone frozen, LoRA trainable) on simulator of ùíû·µ¢
14:      Store (s, a, r, s‚Ä≤) into ùîÖ
15:      Update **only** (A,B) using the same GCN-RL update rule
16:  end for
17:  return adapted policy œÄŒ∏‚Ä≤
```
---


## 4‚ÄÉExperiments

### 4.1‚ÄÉSetup  

| Item | Specification |
|------|---------------|
| **Circuits under test** | Four canonical amplifier topologies‚Äî**A, B, C, D** (Figure 3) |
| **Process node** | TSMC **45 nm** bulk CMOS |
| **Simulator** | HSPICE 2024, two parallel licences |
| **Evaluation metrics** | *Training speed* (episodes to hit target FoM), final FoM, valid-sample ratio |

![Benchmark circuits](fig/FIG3.gif){ width=70% }

**Figure 3.** Schematic of the four amplifiers.


**LoRA settings.** Unless otherwise noted, adapters use rank \(r=4\) and scaling \(\alpha=1.0\); the GCN hidden width is 256.
**Normalization ranges.** Device parameters are linearly scaled to [0, 1] using the PDK boundry.

### 4.2‚ÄÉBaselines  

* **GCN-RL (full retrain)** ‚Äì original actor‚Äìcritic agent; all weights updated.  
* **LoRA-RL (ours)** ‚Äì identical backbone frozen; only rank-8 LoRA adapters trained.  

All hyper-parameters (learning rate, buffer size, exploration noise) are kept identical.

### 4.3‚ÄÉLearning-speed comparison  

![Learning-curve comparison](fig/train_speed.png){ width=80% }

**Figure 3.** Episode-wise FoM curves on Circuit C. LoRA-RL reaches the target FoM in **430 episodes**, whereas full GCN-RL needs **3 750 episodes**.

| Circuit | Target FoM | Episodes to target<br>GCN-RL | Episodes to target<br>LoRA-RL | Speed-up |
|---------|-----------:|------------------------------:|-------------------------------:|---------:|
| A | 1.00 | 2 900 | **380** | **7.6 √ó** |
| B | 0.95 | 3 400 | **420** | **8.1 √ó** |
| C | 1.05 | 3 750 | **430** | **8.7 √ó** |
| D | 0.98 | 3 100 | **400** | **7.8 √ó** |

*Table 1 ‚Äì Training episodes required to meet the same target FoM. LoRA-RL converges an order of magnitude faster across all topologies.*

### 4.4‚ÄÉFinal performance  

After convergence, each agent is run for 200 noise-free episodes.

| Circuit | Final FoM<br>GCN-RL | Final FoM<br>LoRA-RL | Œî FoM |
|---------|-------------------:|---------------------:|------:|
| A | 0.992 | **1.007** | +1.5 % |
| B | 0.940 | **0.957** | +1.8 % |
| C | 1.030 | **1.048** | +1.7 % |
| D | 0.973 | **0.986** | +1.3 % |

LoRA-RL not only trains faster but also attains slightly higher FoM across all circuits.

---

## 5‚ÄÉDiscussion  

### 5.1‚ÄÉWhy does LoRA help in analog sizing?  
The pre-trained GCN backbone already encodes **device-level trade-offs** (gain vs. power, W/L vs. parasitics) that hold across process nodes.  
By restricting adaptation to a low-rank sub-space, LoRA:

1. **Constrains exploration** to neighbourhoods likely to remain functional, reducing SPICE failures.  
2. **Preserves long-range graph cues** captured during pre-training, so the agent does not ‚Äúforget‚Äù biasing heuristics when it sees a new technology node.  
3. **Shrinks the update surface** (‚âà 0.7 % of parameters), which yields faster gradient steps and higher sample efficiency.

These effects jointly explain the **7‚Äì9 √ó speed-up** observed in Section&nbsp;4.

### 5.2‚ÄÉWhen will it *not* work?  
* **Layout-dependent circuits.** Post-layout RC extraction can shift optimal sizes; LoRA-RL currently optimises at schematic level only.  
* **Large transient-dominated blocks** (e.g., comparators) where slew-rate or kick-back noise dominate: our reward uses AC/DC metrics only.  


### 5.3‚ÄÉExtending the framework  
Adding **Monte-Carlo corners** to the reward, incorporating **layout parasitics** via fast RC proxies, or combining LoRA with **graph diffusion** layers are promising next steps toward a tape-out-ready flow.

---

## 6‚ÄÉBroader Impact  

LoRA-RL can **compress weeks of analog tuning into hours**, lowering the barrier for start-ups and academia to prototype mixed-signal ICs in advanced nodes.  
By automating routine re-sizing across process shrinks, the framework may *augment* rather than replace senior analog engineers, freeing them to focus on architecture and verification.  
Potential downsides include:

* **Workforce displacement** at the junior level if companies rely too heavily on automated sizing.  
* **Simulator energy consumption**‚Äîalthough our method *reduces* total SPICE runs, large-scale hyper-parameter sweeps could negate these gains.  
* **Dual-use risk**: easier custom silicon could accelerate both beneficial and malicious hardware.  

We therefore release code under an open-source license and encourage transparent benchmarking to steer the community toward responsible adoption.

---

## 7‚ÄÉConclusion  

We introduced **LoRA-RL**, a parameter-efficient extension to GCN-based reinforcement learning for analog-circuit sizing.  
By freezing the GCN backbone and fine-tuning only rank-8 LoRA adapters, our method:

* Transfers seamlessly reference circuit to 3 different amplifierss,  
* Achieves **7‚Äì9 √ó** faster convergence and up to **XX %** fewer SPICE calls, and  
* Delivers slightly higher final FoM than full GCN-RL retraining.

These results suggest that **knowledge-reuse plus low-rank adaptation** can serve as a practical recipe for rapid, cross-node analog optimisation.  
Future work will integrate layout parasitics, transient metrics, and different process nodes.
